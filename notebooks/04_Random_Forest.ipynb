{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autores:  \n",
    "Blanco García, Gabriel: gabriel.blanco@cunef.edu  \n",
    "Ferrín Meilán, Michelle: michelle.ferrin@cunef.edu\n",
    "\n",
    "## Colegio Universitario de Estudios Financieros\n",
    "### Máster en Data Science para Finanzas\n",
    "Madrid, diciembre de 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos modelos surgen como una alternativa a los árboles de decisión, y el problema que tienen cuando se usan de manera individual. Al utilizar un árbol de decisión, los resultados no son consistentes, y pueden variar en función de cambios en la \n",
    "composición de los conjuntos de entrenamiento y validación.  \n",
    "\n",
    "El Random Forest plantea como solución utilizar muchos árboles, y que la decisión final se tome mediante un sistema de voto. Este sistema se puede modificar, para ponderar el peso de los votos de los árboles en función de, por ejemplo, su precisión.\n",
    "\n",
    "El Random Forest es bagging, lo que quiere decir que los algoritmos se procesan en paralelo. Cada árbol realiza su partición en conjunto de train y test, y se ejecuta. No hay ningún tipo de regla que influya en qué observaciones puede usar un algortimo, son independeientes de las que haya utilizado otro arbol "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a la lecutra de los datos limpios para entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulacion\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# El modelo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluación preliminar\n",
    "from sklearn import metrics \n",
    "\n",
    "# Cargar pipes\n",
    "import pickle \n",
    "\n",
    "# Guardar los modelos\n",
    "%run ../src/operar_modelos.ipynb\n",
    "\n",
    "# Omitir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos limpios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/train/X_train.csv', engine='python')\n",
    "y_train = pd.read_csv('../data/train/y_train.csv', engine='python')\n",
    "\n",
    "X_test = pd.read_csv('../data/test/X_test.csv', engine='python')\n",
    "y_test = pd.read_csv('../data/test/y_test.csv', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesador = cargar_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo, que consta del preprocesado y del casificador Random Forest. No empleamos validación cruzada porque el tiempo de cómputo se extiende demasiado, pero sería la mejor manera de hacerlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levantamos el objeto (no es el entrenamiento)\n",
    "random_forest = Pipeline(steps=[\n",
    "    \n",
    "    # Primer paso: lo llamamos preprocesador y aplicamos el preprocesador generado arriba (con los transformadores dentro)\n",
    "    ('preprocesador', preprocesador), \n",
    "    \n",
    "    # Segundo paso: lo llamamos clasificador, aplicamos la función RandomForestClassifier()\n",
    "    ('clasificador', RandomForestClassifier(random_state = 1234, # primero sin parámetros \n",
    "                                            n_jobs = 3))]) # 3 procesadores del ordenador para ejecutarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocesador',\n",
       "                 ColumnTransformer(transformers=[('numericas',\n",
       "                                                  Pipeline(steps=[('imputador',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('escalador',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'annual_inc_joint',\n",
       "       'dti_joint', 'mort_acc'],\n",
       "      dtype='object')),\n",
       "                                                 ('categoricas',\n",
       "                                                  Pipeline(steps=[('imputador',\n",
       "                                                                   SimpleImputer(fill_value='perdido',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['term', 'grade', 'emp_length', 'home_ownership', 'purpose', 'pub_rec',\n",
       "       'application_type', 'pub_rec_bankruptcies', 'rating_fico'],\n",
       "      dtype='object'))])),\n",
       "                ('clasificador',\n",
       "                 RandomForestClassifier(n_jobs=3, random_state=1234))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999985575917552"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_train, y_train) # 99.99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785566698038706"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_test, y_test) # 77.85%, ejemplo claro de overfitting. El modelo no generaliza bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guardar_modelo(random_forest, '../models/trained_models/Random_Forest.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
