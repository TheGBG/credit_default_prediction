{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autores:  \n",
    "Blanco García, Gabriel: gabriel.blanco@cunef.edu  \n",
    "Ferrín Meilán, Michelle: michelle.ferrin@cunef.edu\n",
    "\n",
    "## Colegio Universitario de Estudios Financieros\n",
    "### Máster en Data Science para Finanzas\n",
    "Madrid, diciembre de 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El XGBoost o extreme gradient boosting es un procedimiento para el ensamblado de algoritmos de Machine Learning. Sus siglas hacen referencia a eXtreme Gradient Boosting. Este método, al contrario que el bagging, no procesa en paralelo los modelos, es más complejo.\n",
    "\n",
    "El procedimiento es secuencial. Se empieza con un modelo, que entrena con unos datos, y se evalua con un conjunto de test. Una vez evaluado el desempeño de ese primer modelo, se localizan aquellas observaciones en las que el modelo ha tenido más problemas y ha fallado. Estas observaciones tienen más probabilidad de aparecer en los datos para el siguiente modelo, y así sucesivamente. Lo que busca es pulir una y otra vez las observaciones que son difíciles de clasificar.  \n",
    "\n",
    "Es un método potente y complejo, flexible en el sentido de que los modelos no tienen por qué ser del mismo tipo. El problema es que es caro en coste computacional,  y puede generar overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook construimos un XGBoost basado en árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulacion\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Clasificador GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Evaluación preliminar del modelo\n",
    "from sklearn import metrics \n",
    "\n",
    "# Cargar pipelines\n",
    "import pickle  \n",
    "\n",
    "# Guardar los modelos\n",
    "%run ../src/operar_modelos.ipynb\n",
    "\n",
    "# Omitir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/train/X_train.csv', engine='python')\n",
    "y_train = pd.read_csv('../data/train/y_train.csv', engine='python')\n",
    "\n",
    "X_test = pd.read_csv('../data/test/X_test.csv', engine='python')\n",
    "y_test = pd.read_csv('../data/test/y_test.csv', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesador = cargar_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo con preprocesado y clasificador GradientBoosting. No empleamos validación cruzada porque el tiempo de cómputo se extiende demasiado, pero sería la mejor manera de hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost = Pipeline(steps=[\n",
    "    ('preprocesador', preprocesador),\n",
    "    \n",
    "    ('clasificador', GradientBoostingClassifier(random_state=1234))]) # primero sin parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocesador',\n",
       "                 ColumnTransformer(transformers=[('numericas',\n",
       "                                                  Pipeline(steps=[('imputador',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('escalador',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'annual_inc_joint',\n",
       "       'dti_joint', 'mort_acc'],\n",
       "      dtype='object')),\n",
       "                                                 ('categoricas',\n",
       "                                                  Pipeline(steps=[('imputador',\n",
       "                                                                   SimpleImputer(fill_value='perdido',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['term', 'grade', 'emp_length', 'home_ownership', 'purpose', 'pub_rec',\n",
       "       'application_type', 'pub_rec_bankruptcies', 'rating_fico'],\n",
       "      dtype='object'))])),\n",
       "                ('clasificador',\n",
       "                 GradientBoostingClassifier(random_state=1234))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887160403008864"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost.score(X_train, y_train) # 78.87% en train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7881521868475427"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost.score(X_test, y_test) # 78.81% en test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión no varía sustancialmente entre train y test, así que se descarta el overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo y pasamos a la selección de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_modelo(XGBoost, '../models/trained_models/XGBoost.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
